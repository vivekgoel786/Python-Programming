Credibility of OOT Results Given Use of Development BU Rankings

The OOT exercise was designed primarily to assess model stability and sensitivity — that is, whether the model produces consistent risk ordering when applied to refreshed inputs, rather than to revalidate the business judgment itself. Accordingly, the development-phase BU rankings were retained as a fixed benchmark, allowing the analysis to focus on the model’s internal consistency and behavior under new data conditions.

For the PBL portfolio, where the factor distributions and overall population profile remained broadly unchanged (overall PSI = 0.042), the OOT results are considered highly credible. The stability of both input distributions and Kendall Tau alignment with development indicates that the model continues to behave predictably and consistently relative to the established BU benchmark.

For the LBL portfolio, while the same BU rankings were used, several key input variables exhibited material change (overall PSI = 0.363), suggesting a genuine shift in portfolio characteristics rather than model instability. In this case, the OOT results remain analytically meaningful — they demonstrate that the model appropriately responded to updated financial indicators — but should be interpreted as a stability test, not a refreshed calibration against current business judgment. A targeted BU re-ranking would be advisable for validation of present-day risk alignment.

In summary, using the development BU ranks provides a credible and methodologically sound basis for assessing OOT model stability and sensitivity, which was the intended purpose of the exercise. However, for evaluating current alignment with expert judgment, a refreshed BU re-ranking would be required only if material input shifts are observed — as in the case of the LBL portfolio.
