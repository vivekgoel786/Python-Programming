# Sort the predicted probabilities and actual values
sorted_indices = np.argsort(y_prob)
y_true_sorted = y_test.values[sorted_indices]
y_prob_sorted = y_prob[sorted_indices]

# Calculate the false positive rate and true positive rate
fpr, tpr, thresholds = roc_curve(y_true_sorted, y_prob_sorted)

# Calculate AUC ROC
auc_roc = roc_auc_score(y_test, y_prob)
print(f"AUC ROC: {auc_roc:.4f}")

# Alternatively, you can calculate AUC using the sorted values
from sklearn.metrics import auc
sorted_auc = auc(fpr, tpr)
print(f"Sorted AUC ROC: {sorted_auc:.4f}")
