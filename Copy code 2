import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

# Observed defaults (binary labels)
defaults = np.array([
    0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 
    0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 
    0, 0, 0, 0, 0, 0, 0
])

# PD scores (higher means lower risk)
pd_scores = np.array([
    6.6, 5.9, 6.1, 7.4, 7.2, 7.9, 5.1, 4.6, 7.9, 7.5,
    6.2, 4.8, 8.2, 6.8, 5.2, 6.0, 3.6, 7.7, 6.2, 6.3,
    8.7, 6.1, 6.2, 6.9, 4.6, 8.2, 5.7
])

# Reshape PD scores for logistic regression
X = pd_scores.reshape(-1, 1)

# Standardize the scores (optional but improves numerical stability)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Fit logistic regression model for Platt Scaling
platt_model = LogisticRegression(solver='lbfgs')
platt_model.fit(X_scaled, defaults)

# Get initial calibrated probabilities
calibrated_probs = platt_model.predict_proba(X_scaled)[:, 1]

# Adjust probabilities to match the target CT value (4%)
target_default_rate = 0.04
current_mean_prob = np.mean(calibrated_probs)
bias_adjustment = target_default_rate / current_mean_prob

# Scale the probabilities to achieve the target CT value
adjusted_probs = calibrated_probs * bias_adjustment

# Ensure probabilities remain within valid range [0,1]
adjusted_probs = np.clip(adjusted_probs, 0, 1)

# Display results
for score, prob in zip(pd_scores, adjusted_probs):
    print(f"PD Score: {score:.2f} -> Adjusted Default Probability: {prob:.4f}")

# Verify that the mean adjusted probability is ~4%
final_ct_value = np.mean(adjusted_probs)
print(f"\nFinal CT Value (Target: 4%): {final_ct_value:.4%}")
