Why I Used 'lbfgs' (Limited-memory BFGS)

✅ Handles Multiclass Problems Well: Even though we have a binary classification problem (default/no default), 'lbfgs' is more stable when working with probability calibration.
✅ Works with CalibratedClassifierCV: 'lbfgs' optimizes the log-likelihood, which is crucial when calibrating probabilities using Platt Scaling.
✅ Better for Small to Medium Datasets: 'lbfgs' works well with limited data points (like our 27 samples).
✅ Handles Regularization Better: Supports L2 regularization, which prevents overfitting.
