The development of PD models for the Lombard (LBL) and Mortgage (PBL) portfolios was undertaken in a context characterized by unique challenges and data limitations. Given the nature of the portfolios and the lack of historical default data, a conventional statistical modeling approach was not feasible. This section outlines the key features, assumptions, and constraints associated with the input data used in model development.

4.2.1 Small and Specialized Portfolio

The customer base for both LBL and PBL is relatively small, consisting primarily of High-Net-Worth Individuals (HNWIs) with bespoke credit structures and complex financial profiles.

The available sample at the time of model development was limited in size, reducing the scope for traditional statistical estimation techniques such as logistic regression or machine learning-based risk models.


4.2.2 Absence of Internal Risk Ratings

Unlike more mature corporate or retail portfolios, there were no pre-existing internal risk grades or scores assigned to customers by the bank.

This absence made it challenging to use supervised learning approaches that rely on historical rating or default outcomes as training targets.


4.2.3 Zero-Default and Low-Default Nature

The portfolios are new and have had no observed defaults to date. This “zero-default” environment significantly restricts the ability to calibrate models using actual historical performance data.

Default rates are inherently low due to the financial strength of the client base and conservative lending policies, leading to a structurally “low-default” portfolio even as the book matures.


4.2.4 Expert Judgment–Driven Model Design

Given these constraints, a traditional statistical model was not viable. Instead, the development followed an Expert Judgment–Based Approach, structured and validated through a data-informed framework.

Inputs were sourced through workshops and consultations with Credit Officers (COs), Relationship Managers (RMs), and Business Unit (BU) stakeholders who possess deep qualitative knowledge of the clients and risk dynamics.

These expert inputs were translated into quantifiable factors and scorecards, which were then supplemented by statistical validation techniques such as entropy analysis, score separation, and robustness checks to ensure empirical grounding.


4.2.5 Calibration and Assumptions

Since actual default data was not available, the model calibration was aligned to a target average PD of 0.39%, based on SCB’s internal benchmarks and expert consensus on portfolio risk.

Factor-level weightings and score-to-rating mappings were defined through iterative calibration exercises to ensure consistency with expert views and intended risk segmentation.


4.2.6 Data Quality and Consistency

While historical depth was limited, the available customer information was of high quality and included both qualitative and quantitative attributes.

To ensure consistency, factor values were collected through a standardized questionnaire, with clear guidelines provided to RMs and Credit for accurate and unbiased responses.